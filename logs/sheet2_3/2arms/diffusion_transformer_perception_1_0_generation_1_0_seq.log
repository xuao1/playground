Running iteration 1 with perception_scale 1.0 and generation_scale 1.0...
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:439: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
Namespace(query_interval=1, input_seq_len=8, encoder_n=1, prefill_n=1, decode_n=1, encoder_len=1, prefill_len=1, decode_len=10, simu_ts_len=500, real_run=True, enable_recompute=False, mode='seq', req_interval=0.1362, model='diffusion_transformer', dim=512, enable_slice=False, warmup_num=10, trail_num=20, profile_mode='flashinfer', only_profile=False, num_trails=200, worker_num=3, verbose=0, config='./config_seq.yaml', diffusion_step=100, diffusion_stage_num=5, input_img_num=4, input_img_size=84, input_traj_cnn_size=16, input_traj_transformer_size=10, input_cond_size=274, input_dim=20, cond_dim=274, n_emb=768, global_cond_dim=548, perception_scale=1.0, generation_scale=1.0)
Start DiffusionPolicy inference...
Perception params: 1.168951e+07
Generation params: 8.059087e+07
====== Graph for resnet generated ======
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
====== Graph for backbone generated ======
Query duration: 78.00 ms
Throughput: 12.821
DiffusionPolicy inference finished.
Iteration 1 completed.
--------------------------------------
Running iteration 2 with perception_scale 1.0 and generation_scale 1.0...
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:439: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
Namespace(query_interval=1, input_seq_len=8, encoder_n=1, prefill_n=1, decode_n=1, encoder_len=1, prefill_len=1, decode_len=10, simu_ts_len=500, real_run=True, enable_recompute=False, mode='seq', req_interval=0.1362, model='diffusion_transformer', dim=512, enable_slice=False, warmup_num=10, trail_num=20, profile_mode='flashinfer', only_profile=False, num_trails=200, worker_num=3, verbose=0, config='./config_seq.yaml', diffusion_step=100, diffusion_stage_num=5, input_img_num=4, input_img_size=84, input_traj_cnn_size=16, input_traj_transformer_size=10, input_cond_size=274, input_dim=20, cond_dim=274, n_emb=768, global_cond_dim=548, perception_scale=1.0, generation_scale=1.0)
Start DiffusionPolicy inference...
Perception params: 1.168951e+07
Generation params: 8.059087e+07
====== Graph for resnet generated ======
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
====== Graph for backbone generated ======
Query duration: 78.12 ms
Throughput: 12.800
DiffusionPolicy inference finished.
Iteration 2 completed.
--------------------------------------
Running iteration 3 with perception_scale 1.0 and generation_scale 1.0...
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:439: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
Namespace(query_interval=1, input_seq_len=8, encoder_n=1, prefill_n=1, decode_n=1, encoder_len=1, prefill_len=1, decode_len=10, simu_ts_len=500, real_run=True, enable_recompute=False, mode='seq', req_interval=0.1362, model='diffusion_transformer', dim=512, enable_slice=False, warmup_num=10, trail_num=20, profile_mode='flashinfer', only_profile=False, num_trails=200, worker_num=3, verbose=0, config='./config_seq.yaml', diffusion_step=100, diffusion_stage_num=5, input_img_num=4, input_img_size=84, input_traj_cnn_size=16, input_traj_transformer_size=10, input_cond_size=274, input_dim=20, cond_dim=274, n_emb=768, global_cond_dim=548, perception_scale=1.0, generation_scale=1.0)
Start DiffusionPolicy inference...
Perception params: 1.168951e+07
Generation params: 8.059087e+07
====== Graph for resnet generated ======
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
====== Graph for backbone generated ======
Query duration: 78.04 ms
Throughput: 12.814
DiffusionPolicy inference finished.
Iteration 3 completed.
--------------------------------------
Running iteration 4 with perception_scale 1.0 and generation_scale 1.0...
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:439: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
Namespace(query_interval=1, input_seq_len=8, encoder_n=1, prefill_n=1, decode_n=1, encoder_len=1, prefill_len=1, decode_len=10, simu_ts_len=500, real_run=True, enable_recompute=False, mode='seq', req_interval=0.1362, model='diffusion_transformer', dim=512, enable_slice=False, warmup_num=10, trail_num=20, profile_mode='flashinfer', only_profile=False, num_trails=200, worker_num=3, verbose=0, config='./config_seq.yaml', diffusion_step=100, diffusion_stage_num=5, input_img_num=4, input_img_size=84, input_traj_cnn_size=16, input_traj_transformer_size=10, input_cond_size=274, input_dim=20, cond_dim=274, n_emb=768, global_cond_dim=548, perception_scale=1.0, generation_scale=1.0)
Start DiffusionPolicy inference...
Perception params: 1.168951e+07
Generation params: 8.059087e+07
====== Graph for resnet generated ======
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
====== Graph for backbone generated ======
Query duration: 78.10 ms
Throughput: 12.804
DiffusionPolicy inference finished.
Iteration 4 completed.
--------------------------------------
Running iteration 5 with perception_scale 1.0 and generation_scale 1.0...
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:439: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
/workspace/xformers/playground/../../repos/x-transformers/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled = False)
Namespace(query_interval=1, input_seq_len=8, encoder_n=1, prefill_n=1, decode_n=1, encoder_len=1, prefill_len=1, decode_len=10, simu_ts_len=500, real_run=True, enable_recompute=False, mode='seq', req_interval=0.1362, model='diffusion_transformer', dim=512, enable_slice=False, warmup_num=10, trail_num=20, profile_mode='flashinfer', only_profile=False, num_trails=200, worker_num=3, verbose=0, config='./config_seq.yaml', diffusion_step=100, diffusion_stage_num=5, input_img_num=4, input_img_size=84, input_traj_cnn_size=16, input_traj_transformer_size=10, input_cond_size=274, input_dim=20, cond_dim=274, n_emb=768, global_cond_dim=548, perception_scale=1.0, generation_scale=1.0)
Start DiffusionPolicy inference...
Perception params: 1.168951e+07
Generation params: 8.059087e+07
====== Graph for resnet generated ======
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
Warning: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py changed
====== Graph for backbone generated ======
Query duration: 78.10 ms
Throughput: 12.804
DiffusionPolicy inference finished.
Iteration 5 completed.
--------------------------------------
All iterations are complete. Output saved to diffusion_transformer_perception_1_0_generation_1_0_seq.log.
Average Query Duration: 78.072 ms (0.07807200 seconds)
Throughput: 12.80868941 requests/second
